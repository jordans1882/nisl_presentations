<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Robustness May Be at Odds with Accuracy</title>
    
    <meta name="description" content="MongoDB Distributed transactions from top to bottom" />
    <meta name="author" content="Henrik Ingo" />

    <link rel="stylesheet" href="impress.js/extras/highlight/styles/github.css">
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


    <link href="css/classic-slides.css" rel="stylesheet" />
    
</head>

<body class="impress-not-supported">
<!--
    This fallback message is only visible when there is `impress-not-supported` class on body.
-->
<div class="fallback-message">
    <p>Your browser <b>doesn't support the features required</b> by impress.js, so you are presented with a simplified version of this presentation.</p>
    <p>For the best experience please use the latest <b>Chrome</b>, <b>Safari</b> or <b>Firefox</b> browser.</p>
</div>

<div id="impress" data-transition-duration="1000">
    <div class="step title" data-x="-3900" data-y="-1500" data-z="0">
        <h1></h1>
        <h2></h2>
        <h3></h3>
    </div>

    <div id="Title" class="step title tree-img skip" data-x="-3200" data-y="-1500" data-z="-5000" data-scale="6.5"> </div>
    <div class="step title robust-img skip" data-x="-9700" data-y="4600" data-z="-5000" data-scale="4.5"> </div>
    <div class="step title tow-img skip" data-x="-3200" data-y="4300" data-z="-5000" data-scale="6.5"> </div>
    <div class="step title accuracy-img skip" data-x="4000" data-y="4800" data-z="-5000" data-scale="4.5"> </div>
    <div id="TOW" class="step" data-x="-3200" data-y="4500" data-z="0"> </div>
    <div id="Robust" class="step" data-x="-9700" data-y="4500" data-z="0"> </div>
    <div id="Accuracy" class="step" data-x="4000" data-y="4500" data-z="0"> </div>

    <div id="Intro" class="step history" data-rel-x="3400">
        <h1>More specifically...</h1>
        <ul>
        <li>An inherent tension between adversarial robustness and standard generalization</li>
        </ul>
    </div>

    <div id="Tension" class="step" data-rel-x="500" data-rel-y="-800" data-rel-z="0" data-scale="1">
        <h1>This Tension</h1>
        <ul>
        <li>They show provably exists!</li>
        <li>They demonstrate this empirically.</li>
        <li>They argue this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers.</li>
        <li>They also argue these feature representations tend to align better with salient data charactersistics and human perception.</li>
        </ul>
    </div>

    <div id="Adversarial-Examples-Problem" class="step" data-rel-x="1500" data-rel-y="400" data-rel-z="0">
        <h1>The Problem of Adversarial Examples</h1>
        <ul>
        <li>One can introduce "small" and often inperceptible purtubations cause the model to make high-confident but erroneous peredictions</li>
        <li>Makes these models suseptible to adversarial attack!</li>
        <li>This has led to many approaches to training models that are robust to adversarial examples.</li>
        </ul>
    </div>

    <div id="History-of-Adversarial-Examples" class="step" data-rel-x="0" data-rel-y="1500" data-rel-z="0">
        <h1>A history of adversarial examples</h1>
        <ul>
        <li>Many attempts: (Goodfellow et al. 2015; Nguyen et al. 2015; Moosavi-Dezfooli et al. 2016; Carlini & Wagner 2017; ...)  </li>
        <li>Many were shown to be ineffective (Carlini & Wagner 2017)</li>
        <li>Only more recently has there been progress towards robust models that are empirically verified and sometimes formally verified (Madry et al., 2018; Wong  & Kolter 2018; Sinha et al. 2018; Tjeng et al. 2019; Raghunathan et al. 2018; ...) </li>
        </ul>
    </div>

    <div id="Robust-Statistics" class="step" data-rel-x="100" data-rel-y="1000" data-rel-z="0">
        <h1>Robust Statistics</h1>
	<ul>
        <li>Robust to outliers (Mean versus Median)</li>
        <li>Robust to model mispecification (Model Averaging, Bayesian Models)</li>
        <li>Huber's M-Statistics.... Huber's Loss</li>
	</ul>
	<script type="math/tex; mode=display">L(y, f(y)) = \begin{cases} max(0, 1 - yf(x))^2 & yf(x) \geq -1\\ -4yf(x) & Otherwise \end{cases}</script>
    </div>

    <div id="Costs-of-Adversarial-Training" class="step" data-rel-x="1200" data-rel-y="800" data-rel-z="0">
        <h1>The costs of Adversarial Training</h1>
        <ul>
            <li>Computational</li>
            <li>Accuracy</li>
        </ul>
    </div>

    <div id="Standard-Accuracy-Maximization" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Maximizing Standard Accuracy</h1>
        <ul>
          <li>Want to train models with low expected loss (i.e. Minimize </li>
        </ul>
	<script type="math/tex; mode=display">\underset{(x,y) \sim D}{\mathbb{E}} [\mathcal{L}(x, y; \theta)]</script>
    </div>

    <div id="Adversarial-Robustness" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Adversarial Robustness</h1>
        <ul>
          <li>Minimize Adversarial Loss</li>
        </ul>
	<script type="math/tex; mode=display">\underset{(x,y) \sim D}{\mathbb{E}} [\underset{\delta \in \Delta}{max}\mathcal{L}(x + \delta, y; \theta)]</script>
	where <script type="math/tex">\Delta</script> is the set of <script type="math/tex">\ell_p</script>-bounded perturbations. I.e.
	<script type="math/tex; mode=display">\Delta = \{ \delta \in \mathbb{R}^d : ||\delta||_p  \leq \epsilon \}</script>
	<script type="math/tex">\Delta</script> is seen as the set of invariants that a good model should satisfy.
    </div>

    <div id="Adversarial-Robustness-cont" class="step" data-rel-x="-1500" data-rel-y="600" data-z="0">
        <h1>Adversarial Robustness (cont.)</h1>
        <ul>
          <li>Other notions include:</li>
          <ul>
            <li>Rotations</li>
            <li>Translations</li>
            <li>Smooth spatial deformations</li>
          </ul>
        </ul>
    </div>

    <div id="Adversarial-Training" class="step" data-rel-x="-1500" data-rel-y="400" data-z="0">
        <h1>Adversarial Training (Goodfellow 2015)</h1>
        <ul>
          <li>Most successfull approach (Ben-Tal et al. 2009):</li>
        </ul>
	<script type="math/tex; mode=display">\underset{\theta}{min} \underset{(x,y) \sim \hat{D}}{\mathbb{E}} [\underset{\delta \in S}{max}\mathcal{L}(x + \delta, y; \theta)]</script>

        <ul>
            <li>A saddle-point problem.</li>
            <li>Repeatedly find worst case input perturbations <script type="math/tex">\delta</script> and then update the model parameters to reduce loss on these perturbed inputs.</li>
	    <li>Kind of feels like the inverse of peeling.</li>
        </ul>
    </div>

    <div id="adversarial-costs" class="step" data-rel-x="-1500" data-rel-y="400" data-z="0">
        <h1>Is this universally better?</h1>
	<img src="images/standard-accuracy.png" alt="Standard Accuracy">
    </div>

    <div id="data-augmentation" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Adversarial Training as Data Augmentation</h1>
        <ul>
          <li>Finding worst-case <script type="math/tex">\delta</script> corresponds to augmenting the training-data in the "most-confusing" and thus "most-helpful" maner.</li>
        </ul>
    </div>

    <div id="bin-class-example" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Binary Classification Example</h1>
	<script type="math/tex; mode=display">y \overset{u.a.r.}{\sim} \{-1, 1\}, x_1 = \begin{cases} +y, & w.p. \; p \\ -y, & w.p. \; 1 - p \end{cases}</script>
	<script type="math/tex; mode=display">x_2, \dots, x_{d+1} \sim N(\eta y, 1)</script>
	where <script type="math/tex">\eta = \Theta(1 / \sqrt{d})</script>
	<p> <script type="math/tex">p</script> corresponds to how correlated the feature <script type="math/tex">x_1</script> is with the label.
    </div>

    <div id="standard-classification" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Standard Classification</h1>
	<ul>
	  <li>Response moderately correlated with <script type="math/tex">x_1</script> and very weakly correlated with remaining variables </li>
	  <li>Natural Classifier </li>
	<script type="math/tex; mode=display">f_{avg}(x) := sign(w_{unif}^Tx), \; \; \text{where } w_{unif}:= [ 0, \frac{1}{d}, \dots, \frac{1}{d} ]</script>
	achieves accuracy arbitrarily close to 100%.
	</ul>
    </div>


    <div id="standard-classification-cont" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Standard Classification (Cont.)</h1>
	<script type="math/tex; mode=display">
	\begin{align*}
	  Pr[f_{avg}(x) = y] &= Pr[sign(w_{unif}x) = y]\\
	    &= Pr[ \frac{y}{d} \sum_{i=1}^d N(\eta y, 1) > 0 ]\\
	    &= Pr[N(\eta, \frac{1}{\eta}) > 0 ]\\
	\end{align*}</script>
	which is >99% when <script type="math/tex">\eta > 3 / \sqrt{d} </script>
    </div>

    
    <div id="adversarially-robust-classification" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Adversarially Robust Classification</h1>
	<ul>
	  <li><script type="math/tex">x_2, \dots, x_{d+1}</script> as a single "meta-feature" enough for standard classifier to get arbitrarily close to perfect classification.</li>
	  <li>However, this feature is sensitive to adversarial perturbations.</li>
	</ul>
    </div>


    <div id="adversarially-robust-classification-cont" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Adversarially Robust Classification (Cont.)</h1>
	Probability of meta-feature correctly predicting <script type="math/tex">y</script> is 
	<script type="math/tex; mode=display">
	\begin{align*}
	  \underset{||\delta||_{\infty} \leq \epsilon}{min} Pr[sign(x + \delta) = y] &\leq Pr[N(\eta, \frac{1}{d}) - \epsilon > 0]\\
            &= Pr[ N( -\eta, \frac{1}{d}) > 0] \\
	\end{align*}</script>
	Which means the simple classifier resulting only on these features cannot get adversarial accuracy better than 1%.
    </div>


    
    <div id="robustness-accuracy-tradeoff" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Robustness Accuracy Tradeoff</h1>
	<p> Theorem (Robustness Accuracy Tradeoff): Any classifier that attains
	at least <script type="math/tex">1 - \delta</script> standard accuracy
	on <script type="math/tex">\mathcal{D}</script> has robust accuracy at
	most <script type="math/tex">\frac{p}{1-p} \delta</script> against all
	<script type="math/tex">\ell_{\infty}</script>-bounded adversary with
	<script type="math/tex">\epsilon \geq 2 \eta </script></p>
    </div>
    
    <div id="nonexistence-of-robust-and-accurate" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Nonexistence of Robust and Accurate classifiers</h1>
	
        <ul>
          <li>One might think the bayes-optimal classifier as a candidate. However, this is not true in the data generating considered.</li>
          <li> This goes against the common assumption in adversarial ML that such perfectly robust and accurate classifiers for standard datasets exist (i.e. humans)</li>
        </ul>
    </div>


    <div id="adversarial-training-matters" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Adversarial Training Matters</h1>
	<p> Theorem (Adversarial Training Matters): For <script type="math/tex">\eta \geq 4/ \sqrt{d}</script> and
	  <script type="math/tex">p \leq 0.975</script> a soft-margin SVM classifier of unit weight norm minimizing the
	  distributional loss achieves a standard accuracy of > 99% and
	  adversarial accuracy of <1% against
	  an <script type="math/tex">\ell_{\infty}</script>-bounded adversary of
	    <script type="math/tex">\epsilon \geq 2 \eta </script>.  Minimizing
				      the distributional adversarial loss
				      instead leads to a robust classifier that
				      has a standard and adversarial accuracy of
				      p against any
				      <script type="math/tex">\epsilon<1</script>

	</p>

    </div>

    <div id="transferability" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Transferability</h1>
        <ul>
          <li>An implication of this analysis is that standard training relies on features that are weakly correlated with the correct label.</li>
          <li>Thus adversarial examples that are created by perturbation will transfer across classifiers trained on independent samples of the distribution.</li>
          <li>This might hint to the origin of the observed phenomenon of transferability.</li>
        </ul>
    </div>
    
    <div id="unexpected-benefits" class="step" data-rel-x="-1800" data-rel-y="0" data-z="0">
        <h1>Unexpected Benefits</h1>
	<img src="images/loss-gradient.png" alt="Loss Gradient">
    </div>
    
    <div id="unexpected-benefits-cont" class="step" data-rel-x="-1800" data-rel-y="0" data-z="0">
        <h1>Unexpected Benefits (Cont.)</h1>
	<img src="images/adversarial-examples.png" alt="Loss Gradient">
    </div>

    <div id="unexpected-benefits-cont2" class="step" data-rel-x="-1800" data-rel-y="0" data-z="0">
        <h1>Unexpected Benefits (Cont.)</h1>
	<img src="images/smooth-interpolation.png" alt="Loss Gradient">
    </div>

    <div id="questions" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Questions</h1>
        <ul>
          <li>What did you like most about the paper?</li>
          <li>What did you like least about the paper?</li>
          <li>What are your thoughts on the presentation of their results?</li>
          <li>What do you think was their greatest contribution in this work?</li>
          <li>Did you find these results to be surprising?</li>
        </ul>
    </div>

    <div id="questions2" class="step" data-rel-x="-1500" data-rel-y="0" data-z="0">
        <h1>Questions</h1>
        <ul>
          <li>What do you think about the standard assumption of adversarial ML that a perfectly robust and accurate classifier exists?</li>
          <li>How do you think these results tie to the no-free-lunch theorem?</li>
          <li>Did you find their examples compelling?</li>
        </ul>
    </div>
</div>


<!--
    Add navigation-ui controls: back, forward and a select list.
    Add a progress indicator bar (current step / all steps)
    Add the help popup plugin
-->
<div id="impress-toolbar"></div>

<div id="impress-help"></div>

<!-- Extra modules
     Load highlight.js, mermaid.js, markdown.js and MathJax.js from extras.
     If you're curious about details, these are initialized in src/plugins/extras/extras.js -->
<script type="text/javascript" src="impress.js/extras/highlight/highlight.pack.js"></script>
<script type="text/javascript" src="impress.js/extras/markdown/markdown.js"></script>
<!--
    To make all described above really work, you need to include impress.js in the page.
    You also need to call a `impress().init()` function to initialize impress.js presentation.
    And you should do it in the end of your document. 
-->
<script type="text/javascript" src="impress.js/js/impress.js"></script>
<script>impress().init();</script>

</body>
</html>
